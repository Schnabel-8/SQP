{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fad365",
   "metadata": {},
   "source": [
    "Sequential Quadratic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a9def",
   "metadata": {},
   "source": [
    "Dependencies: `jax`, `scipy`, `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf415dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jacfwd, jacrev, hessian\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab548147",
   "metadata": {},
   "source": [
    "Define your own Objective Functions and Constrains here :\n",
    "\n",
    "(we use rosenbrock function here as an example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ede887",
   "metadata": {},
   "source": [
    "$f(x)=\\sum^{N-1}_{i=1}100(x_{i+1}-{x_i}^2)^2+(1-x_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fc1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the rosenbrock function\n",
    "def f(x):\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443849e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "\n",
    "key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3dd863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jacfwd result, with shape (4, 3)\n",
      "[[ 0.05981758  0.12883787  0.08857603]\n",
      " [ 0.04015916 -0.04928625  0.00684531]\n",
      " [ 0.12188288  0.01406341 -0.3047072 ]\n",
      " [ 0.00140431 -0.00472531  0.00263782]]\n",
      "jacrev result, with shape (4, 3)\n",
      "[[ 0.05981757  0.12883787  0.08857603]\n",
      " [ 0.04015916 -0.04928625  0.00684531]\n",
      " [ 0.12188289  0.01406341 -0.3047072 ]\n",
      " [ 0.00140431 -0.00472531  0.00263782]]\n",
      "hessian, with shape (4, 3, 3)\n",
      "[[[ 0.02285465  0.04922541  0.03384247]\n",
      "  [ 0.04922541  0.10602397  0.07289147]\n",
      "  [ 0.03384247  0.07289147  0.05011288]]\n",
      "\n",
      " [[-0.03195215  0.03921401 -0.00544639]\n",
      "  [ 0.03921401 -0.04812629  0.00668421]\n",
      "  [-0.00544639  0.00668421 -0.00092836]]\n",
      "\n",
      " [[-0.01583708 -0.00182736  0.03959271]\n",
      "  [-0.00182736 -0.00021085  0.00456839]\n",
      "  [ 0.03959271  0.00456839 -0.09898177]]\n",
      "\n",
      " [[-0.00103524  0.00348343 -0.00194457]\n",
      "  [ 0.00348343 -0.01172127  0.0065432 ]\n",
      "  [-0.00194457  0.0065432  -0.00365263]]]\n",
      "W:  [-0.36838785 -2.275689    0.01144757]\n"
     ]
    }
   ],
   "source": [
    "from jax import jacfwd, jacrev\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 0.5 * (jnp.tanh(x / 2) + 1)\n",
    "\n",
    "# Outputs probability of a label being true.\n",
    "def predict(W, b, inputs):\n",
    "    return sigmoid(jnp.dot(inputs, W) + b)\n",
    "\n",
    "# Build a toy dataset.\n",
    "inputs = jnp.array([[0.52, 1.12,  0.77],\n",
    "                   [0.88, -1.08, 0.15],\n",
    "                   [0.52, 0.06, -1.30],\n",
    "                   [0.74, -2.49, 1.39]])\n",
    "targets = jnp.array([True, True, False, True])\n",
    "\n",
    "# Training loss is the negative log-likelihood of the training examples.\n",
    "def loss(W, b):\n",
    "    preds = predict(W, b, inputs)\n",
    "    label_probs = preds * targets + (1 - preds) * (1 - targets)\n",
    "    return -jnp.sum(jnp.log(label_probs))\n",
    "\n",
    "# Initialize random model coefficients\n",
    "key, W_key, b_key = random.split(key, 3)\n",
    "W = random.normal(W_key, (3,))\n",
    "b = random.normal(b_key, ())\n",
    "\n",
    "\n",
    "# Isolate the function from the weight matrix to the predictions\n",
    "f = lambda W: predict(W, b, inputs)\n",
    "\n",
    "J = jacfwd(f)(W)\n",
    "print(\"jacfwd result, with shape\", J.shape)\n",
    "print(J)\n",
    "\n",
    "J = jacrev(f)(W)\n",
    "print(\"jacrev result, with shape\", J.shape)\n",
    "print(J)\n",
    "\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "H = hessian(f)(W)\n",
    "print(\"hessian, with shape\", H.shape)\n",
    "print(H)\n",
    "\n",
    "print(\"W: \",W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56bd0422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n",
      "jacobian, with shape (3,)\n",
      "[ 3. 12. 27.]\n",
      "hessian, with shape (3, 3)\n",
      "[[ 6.  0.  0.]\n",
      " [ 0. 12.  0.]\n",
      " [ 0.  0. 18.]]\n"
     ]
    }
   ],
   "source": [
    "from jax import jacfwd, jacrev\n",
    "\n",
    "def f(x):\n",
    "    return jnp.power(x,3).sum()\n",
    "print(f(jnp.array([1.,2.,3.])))\n",
    "\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "def jacobian(f):\n",
    "    return jacfwd(f)\n",
    "\n",
    "J = jacobian(f)(jnp.array([1.,2.,3.]))\n",
    "print(\"jacobian, with shape\", J.shape)\n",
    "print(J)\n",
    "\n",
    "H = hessian(f)(jnp.array([1.,2.,3.]))\n",
    "print(\"hessian, with shape\", H.shape)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7a5164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  [[2. 1.]]\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.3427175748433131\n",
      "            Iterations: 5\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.3427175748433131\n",
      "     jac: array([-0.82696629, -0.41348338])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 9\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.41494432, 0.17011137])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from scipy.optimize import Bounds\n",
    "\n",
    "bounds = Bounds([0, -0.5], [1.0, 2.0])\n",
    "\n",
    "def rosen(x):\n",
    "\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "def jacobian(f):\n",
    "    return jacfwd(f)\n",
    "\n",
    "rosen_der=jacobian(rosen)\n",
    "\n",
    "\n",
    "ineq_cons = {'type': 'ineq',\n",
    "\n",
    "             'fun' : lambda x: np.array([1 - x[0] - 2*x[1],\n",
    "\n",
    "                                         1 - x[0]**2 - x[1],\n",
    "\n",
    "                                         1 - x[0]**2 + x[1]]),\n",
    "\n",
    "             'jac' : lambda x: np.array([[-1.0, -2.0],\n",
    "\n",
    "                                         [-2*x[0], -1.0],\n",
    "\n",
    "                                         [-2*x[0], 1.0]])}\n",
    "\n",
    "def eqf(x):\n",
    "    return jnp.array([2*x[0] + x[1] - 1])\n",
    "    \n",
    "def jeq(x):\n",
    "    return np.array(jacobian(eqf)(x))\n",
    "    \n",
    "\n",
    "eq_cons = {'type': 'eq',\n",
    "\n",
    "           'fun' : lambda x: np.array([2*x[0] + x[1] - 1]),\n",
    "\n",
    "           #'jac' : lambda x: np.array([2.0, 1.0])}\n",
    "           'jac' : lambda x: np.array(jeq(x))}\n",
    "\n",
    "x0 = np.array([0.5, 0])\n",
    "print(\"1: \",jeq(x0))\n",
    "res = minimize(rosen, x0, method='SLSQP', jac=rosen_der,\n",
    "\n",
    "              constraints=[eq_cons], options={'ftol': 1e-9, 'disp': True})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9feb15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41494432 0.17011135] -0.41348410536118446 2.4584779439852858e-11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rosen(x):\n",
    "\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "def jacobian(f):\n",
    "    return jacfwd(f)\n",
    "\n",
    "df=jacobian(rosen)\n",
    "\n",
    "def c(x):\n",
    "    return 2*x[0]+x[1]-1\n",
    "\n",
    "A=jacobian(c)\n",
    "C=hessian(c)\n",
    "W=hessian(rosen)\n",
    "\n",
    "x0 = np.array([0.5, 0])\n",
    "\n",
    "def phi(x,lamda):\n",
    "    return np.linalg.norm((df(x)-A(x)*lamda),ord=2)**2+c(x)**2\n",
    "beta=0.8\n",
    "epsi=1e-9\n",
    "xk=x0\n",
    "lamdak=1\n",
    "\n",
    "def left(x,lamda):\n",
    "    return np.vstack((np.hstack((W(x)-lamda*C(x),np.reshape(-A(x),(2,1)))),np.hstack((np.reshape(-A(x),(1,2)),np.reshape([0],(1,1))))))\n",
    "\n",
    "def right(x,lamda):\n",
    "    return -np.vstack((np.reshape(df(x),(2,1))-lamda*np.reshape(A(x),(2,1)),-np.reshape(c(x),(1,1))))\n",
    "\n",
    "while phi(xk,lamdak)>epsi:\n",
    "    dx=np.reshape(np.linalg.solve(left(xk,lamdak),right(xk,lamdak)),(3))\n",
    "    alpha=1\n",
    "    xkk=xk+alpha*np.array([dx[0],dx[1]])\n",
    "    lamdakk=lamdak+alpha*dx[2]\n",
    "    while(phi(xkk,lamdakk)>(1-beta*alpha)*phi(xk,lamdak)):\n",
    "        alpha=alpha/4\n",
    "        xkk=xk+alpha*np.array([dx[0],dx[1]])\n",
    "        lamdakk=lamdak+alpha*dx[2]\n",
    "    xk=xkk\n",
    "    lamdak=lamdakk\n",
    "#dx=np.reshape(np.linalg.solve(left(xk,lamdak),right(xk,lamdak)),(3))\n",
    "#print(np.reshape(dx,(3)))\n",
    "#print(xk+alpha*np.array([dx[0],dx[1]]))\n",
    "print(xk,lamdak,phi(xk,lamdak))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c23cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W=jax.hessian(f)\n",
    "g=jacfwd(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c131eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "def constrain_diff(*args):\n",
    "        args=list(args)\n",
    "        cons_jac=lambda x: np.array(jax.jacfwd(args[0])(x))\n",
    "        cons_hess=lambda x:np.array(jax.hessian(args[0])(x))\n",
    "        return [cons_jac,cons_hess]\n",
    "def genW(f_W,cons_hess_W,x0_W):\n",
    "        len_hess_W=len(cons_hess_W(x0_W))\n",
    "        f_jac_W=lambda x:np.array(jax.hessian(f_W)(x))\n",
    "        def W(x_W,lmd_W):\n",
    "            W_=f_jac_W(x_W)\n",
    "            for i_W in range(len_hess_W):\n",
    "                W_-=lmd_W[i_W]*cons_hess_W(x_W)[i_W]\n",
    "            return W_\n",
    "        return W\n",
    "# d is a row vector\n",
    "# this function compute the objective of subproblem\n",
    "# for given W_k and g_k\n",
    "def obj(Wk,gk):\n",
    "    return lambda d:0.5*np.dot(d,np.dot(Wk,d.T))+np.dot(gk,d)\n",
    "# L1 penal function\n",
    "def P(f_P,sigma_P,eq_P,ineq_P):\n",
    "    return lambda x:f_P(x)+sigma_P*(np.sum(eq_P[0](x))+np.sum(np.abs(ineq_P[0](x))>0))\n",
    "def gen_cons(cons_,cons_jac_,xk_):\n",
    "    return lambda d:cons_(xk_)+np.dot(xk_,d)\n",
    "def sqp_ker(f,eq,ineq,x0,epsi=1e-9,sigma=1,rho=0.8):\n",
    "    # diffrentiate the constrains\n",
    "    [eq_jac_ker,eq_hess_ker]=constrain_diff(eq)\n",
    "    [ineq_jac_ker,ineq_hess_ker]=constrain_diff(ineq)\n",
    "    # generate matrix W and vector g\n",
    "    W_ker=genW(f,lambda x: np.vstack((eq_hess_ker(x),ineq_hess_ker(x))),x0)\n",
    "    g_ker=lambda d: np.array(jacfwd(f)(d))\n",
    "    \n",
    "    itr=0\n",
    "    dk=np.inf\n",
    "    while(np.linalg.norm(dk,ord=2)>epsi or itr==0):\n",
    "        itr+=1\n",
    "        objk=lambda d:obj(d,W(xk,lamdak),g(xk))\n",
    "        jack=lambda d:np.array(jacfwd(objk)(d))\n",
    "        hessk=lambda d:np.array(jax.hessian(objk)(d))\n",
    "        dk0=dk\n",
    "        res = minimize(objk, dk0, method='trust-constr', jac=jack, hess=hessk,\n",
    "                      constraints=constr(eq,ineq),\n",
    "                      options={'verbose': 0})\n",
    "        alphak=1\n",
    "        one_dim_search(P,)\n",
    "        xk=xk+alphak*dk\n",
    "# test genW and cons_diff\n",
    "[eq_jac_ker,eq_hess_ker]=constrain_diff(cons_f, 1, 1)\n",
    "[ineq_jac_ker,ineq_hess_ker]=constrain_diff(cons_f, 1, 1)\n",
    "#print(len(np.vstack((eq_hess_ker(x0),ineq_hess_ker(x0)))))\n",
    "W_ker=genW(f,lambda x:np.vstack((eq_hess_ker(x),ineq_hess_ker(x))),x0)   \n",
    "#print(W_ker(x0,np.array([1,1,1,1])))\n",
    "g_ker=obj([[1,1],[2,2]],[1,1])(np.array([1,1]))\n",
    "#print([cons_f, 1, 1][0](np.array([1,1])))\n",
    "P_ker=P(rosen,1,[cons_f, 1, 1],[cons_f, 1, 1])\n",
    "print(P_ker(np.array([1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "886fb031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "[2. 0.]\n",
      "[DeviceArray([[2., 0.],\n",
      "             [0., 0.]], dtype=float32), DeviceArray([[2., 0.],\n",
      "             [0., 0.]], dtype=float32)]\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 10, function evaluations: 10, CG iterations: 0, optimality: 0.00e+00, constraint violation: 9.08e-11, execution time: 0.45 s.\n",
      "[ 1.00000000e+00 -1.27445239e-12]\n",
      "[[ 302. -200.]\n",
      " [-200.  200.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import Bounds\n",
    "\n",
    "bounds = Bounds([0, -0.5], [1.0, 2.0])\n",
    "def rosen(x):\n",
    "\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "def rosen_hess(x):\n",
    "\n",
    "    return np.array(jax.hessian(rosen)(x))\n",
    "\n",
    "from scipy.optimize import LinearConstraint\n",
    "\n",
    "linear_constraint = LinearConstraint([2, 1], [1], [1])\n",
    "\n",
    "def cons_f(x):\n",
    "\n",
    "    return [x[0]**2 + x[1], x[0]**2 - x[1]]\n",
    "\n",
    "def cons_J(x):\n",
    "\n",
    "    return [[2*x[0], 1], [2*x[0], -1]]\n",
    "\n",
    "def cons_H(x, v):\n",
    "\n",
    "    return v[0]*np.array([[2, 0], [0, 0]]) + v[1]*np.array([[2, 0], [0, 0]])\n",
    "\n",
    "from scipy.optimize import NonlinearConstraint\n",
    "\n",
    "def func2(*args):\n",
    "    args=list(args)\n",
    "    length=len(jacfwd(args[0])(args[5]))\n",
    "    a=0*args[5]\n",
    "    for i in range(length):\n",
    "        print(i)\n",
    "        a=a+jacfwd(args[0])(args[5])[i]\n",
    "        \n",
    "    print(a)\n",
    "    print(jax.hessian(args[0])(args[5]))\n",
    "    args.pop()\n",
    "    return NonlinearConstraint(*args)\n",
    "cj=lambda x: np.array(jax.jacfwd(cons_f)(x))\n",
    "def ch(x,v):\n",
    "    hess=np.array(jax.hessian(cons_f)(x))\n",
    "    length=len(hess)\n",
    "    ret=0*hess[0]\n",
    "    for i in range(length):\n",
    "        ret=ret+v[i]*hess[i]\n",
    "    return ret\n",
    "#nonlinear_constraint = NonlinearConstraint(cons_f, 1, 1, jac=cons_J, hess=cons_H)\n",
    "\n",
    "nonlinear_constraint=func2(cons_f, 1, 1,cj,ch,x0)\n",
    "x0 = np.array([0.5, 0])\n",
    "\n",
    "res = minimize(rosen, x0, method='trust-constr', jac=rosen_der, hess=rosen_hess,\n",
    "\n",
    "               constraints=[nonlinear_constraint],\n",
    "\n",
    "               options={'verbose': 1})\n",
    "print(res.x)\n",
    "print(rosen_hess(x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1,1])\n",
    "b=np.array([3,4])\n",
    "a-=b\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot(rosen_der(np.array([1.,2.])),np.array([1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nigger(a,b,c,d):\n",
    "    return a+b+c+d\n",
    "e=[1,2,3,4]\n",
    "print(nigger(*e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=lambda x,y:x**2+y\n",
    "print(a(5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d301266",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.array([-1,-1])>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad7c179",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cons_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12979/1479964031.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcons_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcons_J\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cons_f' is not defined"
     ]
    }
   ],
   "source": [
    "print(cons_f(np.array([-1,-1]))+np.dot(cons_J(np.array([-1,-1])),np.array([-1,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a51ccc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function genW.<locals>.W at 0x7fcfac467280>\n",
      "2.0\n",
      "[2.         1.14068079]\n"
     ]
    }
   ],
   "source": [
    "x0=np.array([1.,1.])\n",
    "def f(x):\n",
    "    return -jnp.sin(x[0])*jnp.cos(x[1])+jnp.sin(x[1])*jnp.cos(x[0])\n",
    "    \n",
    "jac_f=lambda x:np.array(jacfwd(f)(x))\n",
    "hess_f=lambda x:np.array(hessian(f)(x))\n",
    "\n",
    "def ineq(x):\n",
    "    return [x[0]+x[1],-x[0]-x[1]-jnp.exp(-7*x[0])+jnp.pi]\n",
    "jac_ineq=lambda x:np.array(jacfwd(ineq)(x))\n",
    "hess_ineq=lambda x:np.array(hessian(ineq)(x))\n",
    "\n",
    "def eq(x):\n",
    "    return [x[0]-x[1]**3]\n",
    "jac_eq=lambda x:np.array(jacfwd(eq)(x))\n",
    "hess_eq=lambda x:np.array(hessian(eq)(x))\n",
    "\n",
    "def genW(f_W,cons_hess_W,x0_W):\n",
    "        len_hess_W=len(cons_hess_W(x0_W))\n",
    "        f_jac_W=lambda x:np.array(jax.hessian(f_W)(x))\n",
    "        def W(x_W,lmd_W):\n",
    "            W_=f_jac_W(x_W)\n",
    "            for i_W in range(len_hess_W):\n",
    "                W_-=lmd_W[i_W]*cons_hess_W(x_W)[i_W]\n",
    "            return W_\n",
    "        return W\n",
    "# d is a row vector\n",
    "# this function compute the objective of subproblem\n",
    "# for given W_k and g_k\n",
    "def obj(Wk,gk):\n",
    "    return lambda d:0.5*np.dot(d,np.dot(Wk,d.T))+np.dot(gk,d)\n",
    "# L1 penal function\n",
    "def P(f_P,sigma_P,eq_P,ineq_P):\n",
    "    return lambda x:f_P(x)+sigma_P*(np.sum(np.abs(eq_P[0](x)))+np.sum(np.maximum(ineq_P[0](x),0,out=None)))\n",
    "def gen_cons(cons_,cons_jac_,xk_):\n",
    "    return lambda d:cons_(xk_)+np.dot(xk_,d)\n",
    "print(genW(hess_f,lambda x: np.vstack((hess_eq(x),hess_ineq(x))),x0))\n",
    "print(P(f,1,[eq,1,1],[ineq,1,1])(x0))\n",
    "print((np.maximum(ineq(x0),0,out=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e12694c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40272724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
