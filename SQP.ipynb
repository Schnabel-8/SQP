{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fad365",
   "metadata": {},
   "source": [
    "Sequential Quadratic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a9def",
   "metadata": {},
   "source": [
    "Dependencies: `jax`, `scipy`, `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cf415dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jacfwd, jacrev\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab548147",
   "metadata": {},
   "source": [
    "Define your own Objective Functions and Constrains here :\n",
    "\n",
    "(we use rosenbrock function here as an example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ede887",
   "metadata": {},
   "source": [
    "$f(x)=\\sum^{N-1}_{i=1}100(x_{i+1}-{x_i}^2)^2+(1-x_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fc1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the rosenbrock function\n",
    "def f(x):\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443849e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "\n",
    "key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3dd863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jacfwd result, with shape (4, 3)\n",
      "[[ 0.05981758  0.12883787  0.08857603]\n",
      " [ 0.04015916 -0.04928625  0.00684531]\n",
      " [ 0.12188288  0.01406341 -0.3047072 ]\n",
      " [ 0.00140431 -0.00472531  0.00263782]]\n",
      "jacrev result, with shape (4, 3)\n",
      "[[ 0.05981757  0.12883787  0.08857603]\n",
      " [ 0.04015916 -0.04928625  0.00684531]\n",
      " [ 0.12188289  0.01406341 -0.3047072 ]\n",
      " [ 0.00140431 -0.00472531  0.00263782]]\n",
      "hessian, with shape (4, 3, 3)\n",
      "[[[ 0.02285465  0.04922541  0.03384247]\n",
      "  [ 0.04922541  0.10602397  0.07289147]\n",
      "  [ 0.03384247  0.07289147  0.05011288]]\n",
      "\n",
      " [[-0.03195215  0.03921401 -0.00544639]\n",
      "  [ 0.03921401 -0.04812629  0.00668421]\n",
      "  [-0.00544639  0.00668421 -0.00092836]]\n",
      "\n",
      " [[-0.01583708 -0.00182736  0.03959271]\n",
      "  [-0.00182736 -0.00021085  0.00456839]\n",
      "  [ 0.03959271  0.00456839 -0.09898177]]\n",
      "\n",
      " [[-0.00103524  0.00348343 -0.00194457]\n",
      "  [ 0.00348343 -0.01172127  0.0065432 ]\n",
      "  [-0.00194457  0.0065432  -0.00365263]]]\n",
      "W:  [-0.36838785 -2.275689    0.01144757]\n"
     ]
    }
   ],
   "source": [
    "from jax import jacfwd, jacrev\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 0.5 * (jnp.tanh(x / 2) + 1)\n",
    "\n",
    "# Outputs probability of a label being true.\n",
    "def predict(W, b, inputs):\n",
    "    return sigmoid(jnp.dot(inputs, W) + b)\n",
    "\n",
    "# Build a toy dataset.\n",
    "inputs = jnp.array([[0.52, 1.12,  0.77],\n",
    "                   [0.88, -1.08, 0.15],\n",
    "                   [0.52, 0.06, -1.30],\n",
    "                   [0.74, -2.49, 1.39]])\n",
    "targets = jnp.array([True, True, False, True])\n",
    "\n",
    "# Training loss is the negative log-likelihood of the training examples.\n",
    "def loss(W, b):\n",
    "    preds = predict(W, b, inputs)\n",
    "    label_probs = preds * targets + (1 - preds) * (1 - targets)\n",
    "    return -jnp.sum(jnp.log(label_probs))\n",
    "\n",
    "# Initialize random model coefficients\n",
    "key, W_key, b_key = random.split(key, 3)\n",
    "W = random.normal(W_key, (3,))\n",
    "b = random.normal(b_key, ())\n",
    "\n",
    "\n",
    "# Isolate the function from the weight matrix to the predictions\n",
    "f = lambda W: predict(W, b, inputs)\n",
    "\n",
    "J = jacfwd(f)(W)\n",
    "print(\"jacfwd result, with shape\", J.shape)\n",
    "print(J)\n",
    "\n",
    "J = jacrev(f)(W)\n",
    "print(\"jacrev result, with shape\", J.shape)\n",
    "print(J)\n",
    "\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "H = hessian(f)(W)\n",
    "print(\"hessian, with shape\", H.shape)\n",
    "print(H)\n",
    "\n",
    "print(\"W: \",W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56bd0422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n",
      "jacobian, with shape (3,)\n",
      "[ 3. 12. 27.]\n",
      "hessian, with shape (3, 3)\n",
      "[[ 6.  0.  0.]\n",
      " [ 0. 12.  0.]\n",
      " [ 0.  0. 18.]]\n"
     ]
    }
   ],
   "source": [
    "from jax import jacfwd, jacrev\n",
    "\n",
    "def f(x):\n",
    "    return jnp.power(x,3).sum()\n",
    "print(f(jnp.array([1.,2.,3.])))\n",
    "\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "def jacobian(f):\n",
    "    return jacfwd(f)\n",
    "\n",
    "J = jacobian(f)(jnp.array([1.,2.,3.]))\n",
    "print(\"jacobian, with shape\", J.shape)\n",
    "print(J)\n",
    "\n",
    "H = hessian(f)(jnp.array([1.,2.,3.]))\n",
    "print(\"hessian, with shape\", H.shape)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7a5164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  [[2. 1.]]\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.3427175748433131\n",
      "            Iterations: 5\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.3427175748433131\n",
      "     jac: array([-0.82696629, -0.41348338])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 9\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.41494432, 0.17011137])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from scipy.optimize import Bounds\n",
    "\n",
    "bounds = Bounds([0, -0.5], [1.0, 2.0])\n",
    "\n",
    "def rosen(x):\n",
    "\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "def jacobian(f):\n",
    "    return jacfwd(f)\n",
    "\n",
    "rosen_der=jacobian(rosen)\n",
    "\n",
    "\n",
    "ineq_cons = {'type': 'ineq',\n",
    "\n",
    "             'fun' : lambda x: np.array([1 - x[0] - 2*x[1],\n",
    "\n",
    "                                         1 - x[0]**2 - x[1],\n",
    "\n",
    "                                         1 - x[0]**2 + x[1]]),\n",
    "\n",
    "             'jac' : lambda x: np.array([[-1.0, -2.0],\n",
    "\n",
    "                                         [-2*x[0], -1.0],\n",
    "\n",
    "                                         [-2*x[0], 1.0]])}\n",
    "\n",
    "def eqf(x):\n",
    "    return jnp.array([2*x[0] + x[1] - 1])\n",
    "    \n",
    "def jeq(x):\n",
    "    return np.array(jacobian(eqf)(x))\n",
    "    \n",
    "\n",
    "eq_cons = {'type': 'eq',\n",
    "\n",
    "           'fun' : lambda x: np.array([2*x[0] + x[1] - 1]),\n",
    "\n",
    "           #'jac' : lambda x: np.array([2.0, 1.0])}\n",
    "           'jac' : lambda x: np.array(jeq(x))}\n",
    "\n",
    "x0 = np.array([0.5, 0])\n",
    "print(\"1: \",jeq(x0))\n",
    "res = minimize(rosen, x0, method='SLSQP', jac=rosen_der,\n",
    "\n",
    "              constraints=[eq_cons], options={'ftol': 1e-9, 'disp': True})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9feb15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41494432 0.17011135] -0.41348410536118446 2.4584779439852858e-11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rosen(x):\n",
    "\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "def jacobian(f):\n",
    "    return jacfwd(f)\n",
    "\n",
    "df=jacobian(rosen)\n",
    "\n",
    "def c(x):\n",
    "    return 2*x[0]+x[1]-1\n",
    "\n",
    "A=jacobian(c)\n",
    "C=hessian(c)\n",
    "W=hessian(rosen)\n",
    "\n",
    "x0 = np.array([0.5, 0])\n",
    "\n",
    "def phi(x,lamda):\n",
    "    return np.linalg.norm((df(x)-A(x)*lamda),ord=2)**2+c(x)**2\n",
    "beta=0.8\n",
    "epsi=1e-9\n",
    "xk=x0\n",
    "lamdak=1\n",
    "\n",
    "def left(x,lamda):\n",
    "    return np.vstack((np.hstack((W(x)-lamda*C(x),np.reshape(-A(x),(2,1)))),np.hstack((np.reshape(-A(x),(1,2)),np.reshape([0],(1,1))))))\n",
    "\n",
    "def right(x,lamda):\n",
    "    return -np.vstack((np.reshape(df(x),(2,1))-lamda*np.reshape(A(x),(2,1)),-np.reshape(c(x),(1,1))))\n",
    "\n",
    "while phi(xk,lamdak)>epsi:\n",
    "    dx=np.reshape(np.linalg.solve(left(xk,lamdak),right(xk,lamdak)),(3))\n",
    "    alpha=1\n",
    "    xkk=xk+alpha*np.array([dx[0],dx[1]])\n",
    "    lamdakk=lamdak+alpha*dx[2]\n",
    "    while(phi(xkk,lamdakk)>(1-beta*alpha)*phi(xk,lamdak)):\n",
    "        alpha=alpha/4\n",
    "        xkk=xk+alpha*np.array([dx[0],dx[1]])\n",
    "        lamdakk=lamdak+alpha*dx[2]\n",
    "    xk=xkk\n",
    "    lamdak=lamdakk\n",
    "#dx=np.reshape(np.linalg.solve(left(xk,lamdak),right(xk,lamdak)),(3))\n",
    "#print(np.reshape(dx,(3)))\n",
    "#print(xk+alpha*np.array([dx[0],dx[1]]))\n",
    "print(xk,lamdak,phi(xk,lamdak))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c23cbeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16042/4091351795.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjacfwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jax' is not defined"
     ]
    }
   ],
   "source": [
    "W=jax.hessian(f)\n",
    "g=jacfwd(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c131eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqp_ker(f,eq,ineq,x0,epsi=1e-9,sigma=1,rho=0.8):\n",
    "    W=lambda x,lamda: np.array(jax.hessian(f)(d)\n",
    "    g=lambda d: np.array(jacfwd(f)(d))\n",
    "    # d is a row vector\n",
    "    # this function compute the objective of subproblem\n",
    "    # for given W_k and g_k\n",
    "    def obj(d,Wk,gk):\n",
    "        return 0.5*np.dot(d,np.dot(Wk,d.T))+np.dot(gk,d)\n",
    "    # generate constraints\n",
    "    def constr(eq,ineq):\n",
    "        eq_constraint=NonlinearConstraint(*eq)\n",
    "        ineq_constraint=NonlinearConstraint(*eq)\n",
    "        return [eq_constraint,ineq_constraint]\n",
    "    # L1 penal function\n",
    "    def P(d):\n",
    "        return np.sum(d)\n",
    "    \n",
    "    itr=0\n",
    "    dk=np.inf\n",
    "    while(np.linalg.norm(dk,ord=2)>epsi or itr==0):\n",
    "        itr+=1\n",
    "        objk=lambda d:obj(d,W(xk,lamdak),g(xk))\n",
    "        jack=lambda d:np.array(jacfwd(objk)(d))\n",
    "        hessk=lambda d:np.array(jax.hessian(objk)(d))\n",
    "        dk0=dk\n",
    "        res = minimize(objk, dk0, method='trust-constr', jac=jack, hess=hessk,\n",
    "                      constraints=constr(eq,ineq),\n",
    "                      options={'verbose': 0})\n",
    "        alphak=1\n",
    "        one_dim_search(P,)\n",
    "        xk=xk+alphak*dk\n",
    "                 \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "886fb031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 37, function evaluations: 29, CG iterations: 36, optimality: 2.38e-07, constraint violation: 1.11e-16, execution time:  1.6 s.\n",
      "[0.41494431 0.17011137]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import Bounds\n",
    "\n",
    "bounds = Bounds([0, -0.5], [1.0, 2.0])\n",
    "def rosen(x):\n",
    "\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "def rosen_hess(x):\n",
    "\n",
    "    return np.array(jax.hessian(rosen)(x))\n",
    "\n",
    "from scipy.optimize import LinearConstraint\n",
    "\n",
    "linear_constraint = LinearConstraint([2, 1], [1], [1])\n",
    "\n",
    "def cons_f(x):\n",
    "\n",
    "    return x[0]*2+x[1]\n",
    "\n",
    "def cons_J(x):\n",
    "\n",
    "    return np.array(jacfwd(cons_f)(x))\n",
    "\n",
    "def cons_H(x, v):\n",
    "\n",
    "    return np.array(jax.hessian(rosen)(x))\n",
    "\n",
    "from scipy.optimize import NonlinearConstraint\n",
    "\n",
    "nonlinear_constraint = NonlinearConstraint(cons_f, 1, 1, jac=cons_J, hess=cons_H)\n",
    "\n",
    "x0 = np.array([0.5, 0])\n",
    "\n",
    "res = minimize(rosen, x0, method='trust-constr', jac=rosen_der, hess=rosen_hess,\n",
    "\n",
    "               constraints=[nonlinear_constraint],\n",
    "\n",
    "               options={'verbose': 1})\n",
    "print(res.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d86f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "a=np.array([1,1])\n",
    "b=np.array([[1,2],[3,4]])\n",
    "print(np.dot(a,np.dot(b,a.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e2c2391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-200.0\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(rosen_der(np.array([1.,2.])),np.array([1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acc0632f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def nigger(a,b,c,d):\n",
    "    return a+b+c+d\n",
    "e=[1,2,3,4]\n",
    "print(nigger(*e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "164f0661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "a=lambda x,y:x**2+y\n",
    "print(a(5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d301266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
